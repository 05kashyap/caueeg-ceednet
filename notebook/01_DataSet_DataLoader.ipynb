{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Dataset and DataLoader\n",
    "\n",
    "This notebook loads the `CAUEEG` dataset, tests some useful preprocessing, and makes up the PyTorch DataLoader instances for the training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "-----\n",
    "\n",
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Minjae\\Documents\\GitHub\\caueeg-ceednet\n"
     ]
    }
   ],
   "source": [
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Load some packages\n",
    "import os\n",
    "import json\n",
    "import pprint\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "# custom package\n",
    "from datasets.caueeg_dataset import *\n",
    "from datasets.caueeg_script import *\n",
    "from datasets.pipeline import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 1.12.1\n",
      "cuda is available.\n"
     ]
    }
   ],
   "source": [
    "print('PyTorch version:', torch.__version__)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "if torch.cuda.is_available(): print('cuda is available.')\n",
    "else: print('cuda is unavailable.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Data file path\n",
    "data_path = r'local/dataset/caueeg-dataset/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "\tdataset_name:\n",
      "\t\tCAUEEG dataset\n",
      "\n",
      "\tsignal_header:\n",
      "\t\tFp1-AVG\n",
      "\t\tF3-AVG\n",
      "\t\t.\n",
      "\t\t.\n",
      "\t\t.\n",
      "\t\tPhotic\n",
      "\n",
      "\tdata:\n",
      "\t\t{'serial': '00001', 'age': 78, 'symptom': ['mci', 'mci_amnestic', 'mci_amnestic_rf']}\n",
      "\t\t{'serial': '00002', 'age': 56, 'symptom': ['normal', 'smi']}\n",
      "\t\t.\n",
      "\t\t.\n",
      "\t\t.\n",
      "\t\t{'serial': '01388', 'age': 73, 'symptom': ['mci', 'mci_amnestic', 'mci_amnestic_ef']}\n",
      "\n",
      "}\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "{\n",
      "\ttask_name:\n",
      "\t\tCAUEEG-Abnormal benchmark\n",
      "\n",
      "\ttask_description:\n",
      "\t\tClassification of [Normal] and [Abnormal] symptoms\n",
      "\n",
      "\tclass_label_to_name:\n",
      "\t\t['Normal', 'Abnormal']\n",
      "\n",
      "\tclass_name_to_label:\n",
      "\t\t{'Normal': 0, 'Abnormal': 1}\n",
      "\n",
      "\ttrain_split:\n",
      "\t\t{'serial': '01258', 'age': 77, 'symptom': ['dementia', 'vd', 'sivd'], 'class_name': 'Abnormal', 'class_label': 1}\n",
      "\t\t{'serial': '00836', 'age': 80, 'symptom': ['normal', 'smi'], 'class_name': 'Normal', 'class_label': 0}\n",
      "\t\t.\n",
      "\t\t.\n",
      "\t\t.\n",
      "\t\t{'serial': '00105', 'age': 71, 'symptom': ['normal', 'smi'], 'class_name': 'Normal', 'class_label': 0}\n",
      "\n",
      "\tvalidation_split:\n",
      "\t\t{'serial': '00152', 'age': 81, 'symptom': ['dementia', 'ad', 'load'], 'class_name': 'Abnormal', 'class_label': 1}\n",
      "\t\t{'serial': '01034', 'age': 81, 'symptom': ['mci', 'mci_amnestic', 'mci_amnestic_ef'], 'class_name': 'Abnormal', 'class_label': 1}\n",
      "\t\t.\n",
      "\t\t.\n",
      "\t\t.\n",
      "\t\t{'serial': '00684', 'age': 65, 'symptom': ['normal', 'cb_normal'], 'class_name': 'Normal', 'class_label': 0}\n",
      "\n",
      "\ttest_split:\n",
      "\t\t{'serial': '00560', 'age': 57, 'symptom': ['normal', 'cb_normal'], 'class_name': 'Normal', 'class_label': 0}\n",
      "\t\t{'serial': '01156', 'age': 62, 'symptom': ['mci', 'mci_amnestic', 'mci_amnestic_rf'], 'class_name': 'Abnormal', 'class_label': 1}\n",
      "\t\t.\n",
      "\t\t.\n",
      "\t\t.\n",
      "\t\t{'serial': '00888', 'age': 52, 'symptom': ['normal', 'cb_normal'], 'class_name': 'Normal', 'class_label': 0}\n",
      "\n",
      "}\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "{\n",
      "\ttask_name:\n",
      "\t\tCAUEEG-Dementia benchmark\n",
      "\n",
      "\ttask_description:\n",
      "\t\tClassification of [Normal], [MCI], and [Dementia] symptoms.\n",
      "\n",
      "\tclass_label_to_name:\n",
      "\t\t['Normal', 'MCI', 'Dementia']\n",
      "\n",
      "\tclass_name_to_label:\n",
      "\t\t{'Normal': 0, 'MCI': 1, 'Dementia': 2}\n",
      "\n",
      "\ttrain_split:\n",
      "\t\t{'serial': '00587', 'age': 53, 'symptom': ['normal', 'cb_normal'], 'class_name': 'Normal', 'class_label': 0}\n",
      "\t\t{'serial': '01301', 'age': 88, 'symptom': ['dementia', 'ad', 'load'], 'class_name': 'Dementia', 'class_label': 2}\n",
      "\t\t.\n",
      "\t\t.\n",
      "\t\t.\n",
      "\t\t{'serial': '00153', 'age': 64, 'symptom': ['mci', 'mci_non_amnestic'], 'class_name': 'MCI', 'class_label': 1}\n",
      "\n",
      "\tvalidation_split:\n",
      "\t\t{'serial': '00341', 'age': 80, 'symptom': ['dementia', 'ad', 'load'], 'class_name': 'Dementia', 'class_label': 2}\n",
      "\t\t{'serial': '00510', 'age': 82, 'symptom': ['dementia', 'vd', 'sivd'], 'class_name': 'Dementia', 'class_label': 2}\n",
      "\t\t.\n",
      "\t\t.\n",
      "\t\t.\n",
      "\t\t{'serial': '01303', 'age': 52, 'symptom': ['normal', 'smi'], 'class_name': 'Normal', 'class_label': 0}\n",
      "\n",
      "\ttest_split:\n",
      "\t\t{'serial': '00789', 'age': 62, 'symptom': ['normal', 'cb_normal'], 'class_name': 'Normal', 'class_label': 0}\n",
      "\t\t{'serial': '00934', 'age': 61, 'symptom': ['normal', 'cb_normal'], 'class_name': 'Normal', 'class_label': 0}\n",
      "\t\t.\n",
      "\t\t.\n",
      "\t\t.\n",
      "\t\t{'serial': '00520', 'age': 55, 'symptom': ['normal', 'smi'], 'class_name': 'Normal', 'class_label': 0}\n",
      "\n",
      "}\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for task in ['annotation.json', 'abnormal.json', 'dementia.json']:\n",
    "    task_path = os.path.join(data_path, task)\n",
    "    with open(task_path, 'r') as json_file:\n",
    "        task_dict = json.load(json_file)\n",
    "        \n",
    "    print('{')\n",
    "    for k, v in task_dict.items():\n",
    "        print(f'\\t{k}:')\n",
    "        if isinstance(v, list) and len(v) > 3:\n",
    "            print(f'\\t\\t{v[0]}')\n",
    "            print(f'\\t\\t{v[1]}')\n",
    "            print(f'\\t\\t.')\n",
    "            print(f'\\t\\t.')\n",
    "            print(f'\\t\\t.')\n",
    "            print(f'\\t\\t{v[-1]}')\n",
    "        else:\n",
    "            print(f'\\t\\t{v}')\n",
    "        print()\n",
    "    print('}')\n",
    "    print('\\n' + '-' * 100 + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "-----\n",
    "\n",
    "## Load the CAUEEG dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Load the whole CAUEEG data as a PyTorch dataset instance without considering the target task (no train/val/test sets and no class label)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset_name': 'CAUEEG dataset',\n",
      " 'signal_header': ['Fp1-AVG', 'F3-AVG', 'C3-AVG', 'P3-AVG', 'O1-AVG', 'Fp2-AVG', 'F4-AVG', 'C4-AVG', 'P4-AVG', 'O2-AVG', 'F7-AVG', 'T3-AVG', 'T5-AVG', 'F8-AVG', 'T4-AVG', 'T6-AVG', 'FZ-AVG', 'CZ-AVG', 'PZ-AVG', 'EKG', 'Photic']}\n",
      "\n",
      " ---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "{'age': 78,\n",
      " 'serial': '00001',\n",
      " 'signal': array([[  0., -11., -13., ...,   0.,   0.,   0.],\n",
      "       [ 29.,  33.,  34., ...,   0.,   0.,   0.],\n",
      "       [ -3.,  -6.,  -3., ...,   0.,   0.,   0.],\n",
      "       ...,\n",
      "       [ -4.,  -2.,   1., ...,   0.,   0.,   0.],\n",
      "       [112.,  67.,  76., ...,   0.,   0.,   0.],\n",
      "       [ -1.,  -1.,  -1., ...,   0.,   0.,   0.]]),\n",
      " 'symptom': ['mci', 'mci_amnestic', 'mci_amnestic_rf']}\n",
      "\n",
      " ---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "{'age': 78,\n",
      " 'serial': '00004',\n",
      " 'signal': array([[ 30.,  34.,  36., ...,   0.,   0.,   0.],\n",
      "       [ 34.,  25.,  24., ...,   0.,   0.,   0.],\n",
      "       [ 11.,  15.,  15., ...,   0.,   0.,   0.],\n",
      "       ...,\n",
      "       [-10.,  -6.,  -4., ...,   0.,   0.,   0.],\n",
      "       [ 23.,  32.,  30., ...,   0.,   0.,   0.],\n",
      "       [ -1.,   0.,  -1., ...,   0.,   0.,   0.]]),\n",
      " 'symptom': ['dementia', 'ad', 'load']}\n",
      "\n",
      " ---------------------------------------------------------------------------------------------------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "config_data, full_eeg_dataset = load_caueeg_full_dataset(dataset_path=data_path, \n",
    "                                                         load_event=False, \n",
    "                                                         file_format='edf',  # can be ommitted\n",
    "                                                         transform=None)\n",
    "\n",
    "pprint.pprint(config_data, width=250)\n",
    "print('\\n', '-' * 100, '\\n')\n",
    "\n",
    "pprint.pprint(full_eeg_dataset[0])\n",
    "print('\\n', '-' * 100, '\\n')\n",
    "\n",
    "pprint.pprint(full_eeg_dataset[3])\n",
    "print('\\n', '-' * 100, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When triggered `load_event` option, the dataset also loads event data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'age': 78,\n",
      " 'event': [[0, 'Start Recording'],\n",
      "           [0, 'New Montage - Montage 002'],\n",
      "           [36396, 'Eyes Open'],\n",
      "           [72518, 'Eyes Closed'],\n",
      "           [73862, 'Eyes Open'],\n",
      "           [75248, 'Eyes Closed'],\n",
      "           [76728, 'swallowing'],\n",
      "           [77978, 'Eyes Open'],\n",
      "           [79406, 'Eyes Closed'],\n",
      "           [79996, 'Photic On - 3.0 Hz'],\n",
      "           [80288, 'Eyes Open'],\n",
      "           [81296, 'Eyes Closed'],\n",
      "           [82054, 'Photic Off'],\n",
      "           [84070, 'Photic On - 6.0 Hz'],\n",
      "           [84488, 'Eyes Open'],\n",
      "           [85538, 'Eyes Closed'],\n",
      "           [86086, 'Photic Off'],\n",
      "           [88144, 'Photic On - 9.0 Hz'],\n",
      "           [90160, 'Photic Off'],\n",
      "           [91458, 'Eyes Open'],\n",
      "           [92218, 'Photic On - 12.0 Hz'],\n",
      "           [92762, 'Eyes Closed'],\n",
      "           [94198, 'Photic Off'],\n",
      "           [94742, 'Eyes Open'],\n",
      "           [95708, 'Eyes Closed'],\n",
      "           [96256, 'Photic On - 15.0 Hz'],\n",
      "           [98272, 'Photic Off'],\n",
      "           [100330, 'Photic On - 18.0 Hz'],\n",
      "           [102346, 'Photic Off'],\n",
      "           [102596, 'Eyes Open'],\n",
      "           [103856, 'Eyes Closed'],\n",
      "           [104361, 'Photic On - 21.0 Hz'],\n",
      "           [106420, 'Photic Off'],\n",
      "           [106880, 'Eyes Open'],\n",
      "           [107804, 'Eyes Closed'],\n",
      "           [108435, 'Photic On - 24.0 Hz'],\n",
      "           [110452, 'Photic Off'],\n",
      "           [111080, 'Eyes Open'],\n",
      "           [112004, 'Eyes Closed'],\n",
      "           [112509, 'Photic On - 27.0 Hz'],\n",
      "           [114528, 'Photic Off'],\n",
      "           [114864, 'Eyes Open'],\n",
      "           [116124, 'Eyes Closed'],\n",
      "           [116544, 'Photic On - 30.0 Hz'],\n",
      "           [118602, 'Photic Off'],\n",
      "           [126672, 'artifact'],\n",
      "           [134030, 'Move'],\n",
      "           [135584, 'Eyes Open'],\n",
      "           [136668, 'Eyes Closed'],\n",
      "           [139818, 'Eyes Open'],\n",
      "           [141414, 'Eyes Closed'],\n",
      "           [145000, 'Paused']],\n",
      " 'serial': '00001',\n",
      " 'signal': array([[  0., -11., -13., ...,   0.,   0.,   0.],\n",
      "       [ 29.,  33.,  34., ...,   0.,   0.,   0.],\n",
      "       [ -3.,  -6.,  -3., ...,   0.,   0.,   0.],\n",
      "       ...,\n",
      "       [ -4.,  -2.,   1., ...,   0.,   0.,   0.],\n",
      "       [112.,  67.,  76., ...,   0.,   0.,   0.],\n",
      "       [ -1.,  -1.,  -1., ...,   0.,   0.,   0.]]),\n",
      " 'symptom': ['mci', 'mci_amnestic', 'mci_amnestic_rf']}\n"
     ]
    }
   ],
   "source": [
    "config_data, full_eeg_dataset = load_caueeg_full_dataset(dataset_path=data_path, \n",
    "                                                         file_format='edf',\n",
    "                                                         transform=None)\n",
    "pprint.pprint(full_eeg_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Load the CAUEEG benchmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Load the CAUEEG-Abnormal benchmark using the PyTorch dataset instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'class_label_to_name': ['Normal', 'Abnormal'],\n",
      " 'class_name_to_label': {'Abnormal': 1, 'Normal': 0},\n",
      " 'task_description': 'Classification of [Normal] and [Abnormal] symptoms',\n",
      " 'task_name': 'CAUEEG-Abnormal benchmark'}\n",
      "\n",
      " ---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "{'age': 57,\n",
      " 'class_label': 0,\n",
      " 'class_name': 'Normal',\n",
      " 'serial': '00560',\n",
      " 'signal': array([[  7.,  41.,  49., ...,   0.,   0.,   0.],\n",
      "       [ 23.,  26.,  27., ...,   0.,   0.,   0.],\n",
      "       [-16., -20., -18., ...,   0.,   0.,   0.],\n",
      "       ...,\n",
      "       [ 32.,  31.,  31., ...,   0.,   0.,   0.],\n",
      "       [177., 228., 142., ...,   0.,   0.,   0.],\n",
      "       [  0.,  -1.,   0., ...,   0.,   0.,   0.]]),\n",
      " 'symptom': ['normal', 'cb_normal']}\n"
     ]
    }
   ],
   "source": [
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='abnormal',\n",
    "                                                                                  load_event=False)\n",
    "pprint.pprint(config_data)\n",
    "print('\\n', '-' * 100, '\\n')\n",
    "pprint.pprint(test_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Load the CAUEEG-Dementia benchmark using the PyTorch dataset instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'class_label_to_name': ['Normal', 'MCI', 'Dementia'],\n",
      " 'class_name_to_label': {'Dementia': 2, 'MCI': 1, 'Normal': 0},\n",
      " 'task_description': 'Classification of [Normal], [MCI], and [Dementia] '\n",
      "                     'symptoms.',\n",
      " 'task_name': 'CAUEEG-Dementia benchmark'}\n",
      "\n",
      " ---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "{'age': 62,\n",
      " 'class_label': 0,\n",
      " 'class_name': 'Normal',\n",
      " 'serial': '00789',\n",
      " 'signal': array([[-87., -69., -70., ...,   0.,   0.,   0.],\n",
      "       [-25., -18., -19., ...,   0.,   0.,   0.],\n",
      "       [ -6.,   1.,   0., ...,   0.,   0.,   0.],\n",
      "       ...,\n",
      "       [  0.,  -5.,  -4., ...,   0.,   0.,   0.],\n",
      "       [-31.,  -8.,  -7., ...,   0.,   0.,   0.],\n",
      "       [  0.,   1.,  -1., ...,   0.,   0.,   0.]]),\n",
      " 'symptom': ['normal', 'cb_normal']}\n"
     ]
    }
   ],
   "source": [
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='dementia',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  transform=None)\n",
    "pprint.pprint(config_data)\n",
    "print('\\n', '-' * 100, '\\n')\n",
    "pprint.pprint(test_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### With `load_event` triggered, the benchmark can use the event data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'age': 57,\n",
      " 'class_label': 0,\n",
      " 'class_name': 'Normal',\n",
      " 'event': [[0, 'Start Recording'],\n",
      "           [0, 'New Montage - Montage 002'],\n",
      "           [5408, 'Eyes Open'],\n",
      "           [6332, 'Eyes Closed'],\n",
      "           [16832, 'Eyes Open'],\n",
      "           [17756, 'Eyes Closed'],\n",
      "           [24200, 'Paused'],\n",
      "           [28400, 'Recording Resumed'],\n",
      "           [67442, 'Eyes Open'],\n",
      "           [68366, 'Eyes Closed'],\n",
      "           [82856, 'Eyes Open'],\n",
      "           [83738, 'Eyes Closed'],\n",
      "           [109833, 'Eyes Open'],\n",
      "           [109833, 'Eyes Closed'],\n",
      "           [132600, 'Paused']],\n",
      " 'serial': '00560',\n",
      " 'signal': array([[  7.,  41.,  49., ...,   0.,   0.,   0.],\n",
      "       [ 23.,  26.,  27., ...,   0.,   0.,   0.],\n",
      "       [-16., -20., -18., ...,   0.,   0.,   0.],\n",
      "       ...,\n",
      "       [ 32.,  31.,  31., ...,   0.,   0.,   0.],\n",
      "       [177., 228., 142., ...,   0.,   0.,   0.],\n",
      "       [  0.,  -1.,   0., ...,   0.,   0.,   0.]]),\n",
      " 'symptom': ['normal', 'cb_normal']}\n"
     ]
    }
   ],
   "source": [
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='abnormal',\n",
    "                                                                                  load_event=True, \n",
    "                                                                                  file_format='edf', \n",
    "                                                                                  transform=None)\n",
    "pprint.pprint(test_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilizing `PyArrow.feather` is much faster than directly using `EDF`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 4.14 s\n",
      "Wall time: 4.14 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='abnormal',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='edf', \n",
    "                                                                                  transform=None)\n",
    "for i, d in enumerate(test_dataset):\n",
    "    if i > 30:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='abnormal',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='feather', \n",
    "                                                                                  transform=None)\n",
    "for i, d in enumerate(test_dataset):\n",
    "    if i > 30:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---\n",
    "\n",
    "## PyTorch Transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Random crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'age': 62,\n",
      " 'class_label': 0,\n",
      " 'class_name': 'Normal',\n",
      " 'serial': '00789',\n",
      " 'signal': array([[ 55,  51,  51, ...,  33,  37,  42],\n",
      "       [  7,  11,  18, ...,  -9,  -9,  -8],\n",
      "       [ -3,   3,  11, ..., -18, -14,  -7],\n",
      "       ...,\n",
      "       [-15,  -9,  -3, ...,  -7,  -9, -11],\n",
      "       [180, 203, 222, ..., -29, -34, -38],\n",
      "       [  1,   1,   0, ...,  -1,   0,   1]]),\n",
      " 'symptom': ['normal', 'cb_normal']}\n",
      "\n",
      ">>> signal shape: (21, 100)\n",
      "\n",
      " ---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "{'age': 62,\n",
      " 'class_label': 0,\n",
      " 'class_name': 'Normal',\n",
      " 'serial': '00789',\n",
      " 'signal': array([[ 16,  16,  16, ...,  10,   8,  11],\n",
      "       [  8,   9,   6, ...,   1,   2,   5],\n",
      "       [ 16,  18,  19, ...,  -4,  -5,  -3],\n",
      "       ...,\n",
      "       [ -1,   4,   9, ...,  -3,  -4,  -7],\n",
      "       [-36, -36, -36, ..., 151, 141, 130],\n",
      "       [  1,   0,   1, ...,  -3,  -4,   0]]),\n",
      " 'symptom': ['normal', 'cb_normal']}\n",
      "\n",
      ">>> signal shape: (21, 100)\n",
      "\n",
      " ---------------------------------------------------------------------------------------------------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "transform = EegRandomCrop(crop_length=100)\n",
    "\n",
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path,\n",
    "                                                                                  task='dementia',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='feather',\n",
    "                                                                                  transform=transform)\n",
    "for i in range(2):\n",
    "    d = test_dataset[0]\n",
    "    pprint.pprint(d)\n",
    "    print()\n",
    "    print('>>> signal shape:', d['signal'].shape)\n",
    "    print('\\n', '-' * 100, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "### Drop channel(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "channel_ekg:  19\n",
      "channel_photic:  20\n"
     ]
    }
   ],
   "source": [
    "anno_path = os.path.join(data_path, 'annotation.json')\n",
    "with open(anno_path, 'r') as json_file:\n",
    "    annotation = json.load(json_file)\n",
    "signal_headers = annotation['signal_header']\n",
    "\n",
    "channel_ekg = signal_headers.index('EKG')\n",
    "channel_photic = signal_headers.index('Photic')\n",
    "\n",
    "print('channel_ekg: ', channel_ekg)\n",
    "print('channel_photic: ', channel_photic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before: (21, 128400)\n",
      "[[  7  41  49 ...  24  27  29]\n",
      " [ 23  26  27 ... -60 -58 -57]\n",
      " [-16 -20 -18 ...  17  18  17]\n",
      " ...\n",
      " [ 32  31  31 ...  18  16  15]\n",
      " [177 228 142 ...   2   1   0]\n",
      " [  0  -1   0 ...  -1   0   1]]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "after: (20, 128400)\n",
      "[[  7  41  49 ...  24  27  29]\n",
      " [ 23  26  27 ... -60 -58 -57]\n",
      " [-16 -20 -18 ...  17  18  17]\n",
      " ...\n",
      " [  3   7   7 ...  14  14  12]\n",
      " [ 32  31  31 ...  18  16  15]\n",
      " [  0  -1   0 ...  -1   0   1]]\n"
     ]
    }
   ],
   "source": [
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='abnormal',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='feather', \n",
    "                                                                                  transform=None)\n",
    "print('before:', test_dataset[0]['signal'].shape)\n",
    "print(test_dataset[0]['signal'])\n",
    "\n",
    "print()\n",
    "print('-' * 100)\n",
    "print()\n",
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='abnormal',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='feather', \n",
    "                                                                                  transform=EegDropChannels(channel_ekg))\n",
    "print('after:', test_dataset[0]['signal'].shape)\n",
    "print(test_dataset[0]['signal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before: (21, 128400)\n",
      "[[  7  41  49 ...  24  27  29]\n",
      " [ 23  26  27 ... -60 -58 -57]\n",
      " [-16 -20 -18 ...  17  18  17]\n",
      " ...\n",
      " [ 32  31  31 ...  18  16  15]\n",
      " [177 228 142 ...   2   1   0]\n",
      " [  0  -1   0 ...  -1   0   1]]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "after: (20, 128400)\n",
      "[[  7  41  49 ...  24  27  29]\n",
      " [ 23  26  27 ... -60 -58 -57]\n",
      " [-16 -20 -18 ...  17  18  17]\n",
      " ...\n",
      " [  3   7   7 ...  14  14  12]\n",
      " [ 32  31  31 ...  18  16  15]\n",
      " [177 228 142 ...   2   1   0]]\n"
     ]
    }
   ],
   "source": [
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='abnormal',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='feather',\n",
    "                                                                                  transform=None)\n",
    "print('before:', test_dataset[0]['signal'].shape)\n",
    "print(test_dataset[0]['signal'])\n",
    "\n",
    "print()\n",
    "print('-' * 100)\n",
    "print()\n",
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='abnormal',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='feather',\n",
    "                                                                                  transform=EegDropChannels(channel_photic))\n",
    "print('after:', test_dataset[0]['signal'].shape)\n",
    "print(test_dataset[0]['signal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before: (21, 128400)\n",
      "[[  7  41  49 ...  24  27  29]\n",
      " [ 23  26  27 ... -60 -58 -57]\n",
      " [-16 -20 -18 ...  17  18  17]\n",
      " ...\n",
      " [ 32  31  31 ...  18  16  15]\n",
      " [177 228 142 ...   2   1   0]\n",
      " [  0  -1   0 ...  -1   0   1]]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "after: (19, 128400)\n",
      "[[  7  41  49 ...  24  27  29]\n",
      " [ 23  26  27 ... -60 -58 -57]\n",
      " [-16 -20 -18 ...  17  18  17]\n",
      " ...\n",
      " [-26 -11 -11 ...  18  18  17]\n",
      " [  3   7   7 ...  14  14  12]\n",
      " [ 32  31  31 ...  18  16  15]]\n"
     ]
    }
   ],
   "source": [
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='abnormal',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='feather',\n",
    "                                                                                  transform=None)\n",
    "print('before:', test_dataset[0]['signal'].shape)\n",
    "print(test_dataset[0]['signal'])\n",
    "\n",
    "print()\n",
    "print('-' * 100)\n",
    "print()\n",
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='abnormal',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='feather',\n",
    "                                                                                  transform=EegDropChannels([channel_ekg, channel_photic]))\n",
    "print('after:', test_dataset[0]['signal'].shape)\n",
    "print(test_dataset[0]['signal'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### To Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before:\n",
      "{'age': 78,\n",
      " 'serial': '00001',\n",
      " 'signal': array([[  0, -11, -13, ...,  18,  21,  22],\n",
      "       [ 29,  33,  34, ...,  -7,  -4,  -4],\n",
      "       [ -3,  -6,  -3, ...,  -1,   1,   2],\n",
      "       ...,\n",
      "       [ -4,  -2,   1, ...,   0,  -1,  -1],\n",
      "       [112,  67,  76, ..., -13, -15, -11],\n",
      "       [ -1,  -1,  -1, ...,  -1,  -1,  -1]]),\n",
      " 'symptom': ['mci', 'mci_amnestic', 'mci_amnestic_rf']}\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "After:\n",
      "{'age': tensor(78.),\n",
      " 'serial': '00001',\n",
      " 'signal': tensor([[  0., -11., -13.,  ...,  18.,  21.,  22.],\n",
      "        [ 29.,  33.,  34.,  ...,  -7.,  -4.,  -4.],\n",
      "        [ -3.,  -6.,  -3.,  ...,  -1.,   1.,   2.],\n",
      "        ...,\n",
      "        [ -4.,  -2.,   1.,  ...,   0.,  -1.,  -1.],\n",
      "        [112.,  67.,  76.,  ..., -13., -15., -11.],\n",
      "        [ -1.,  -1.,  -1.,  ...,  -1.,  -1.,  -1.]]),\n",
      " 'symptom': ['mci', 'mci_amnestic', 'mci_amnestic_rf']}\n"
     ]
    }
   ],
   "source": [
    "config_data, full_eeg_dataset = load_caueeg_full_dataset(dataset_path=data_path, \n",
    "                                                         load_event=False, \n",
    "                                                         file_format='feather',\n",
    "                                                         transform=None)\n",
    "print('Before:')\n",
    "pprint.pprint(full_eeg_dataset[0])\n",
    "\n",
    "print()\n",
    "print('-' * 100)\n",
    "print()\n",
    "\n",
    "config_data, full_eeg_dataset = load_caueeg_full_dataset(dataset_path=data_path, \n",
    "                                                         load_event=False, \n",
    "                                                         file_format='feather',\n",
    "                                                         transform=EegToTensor())\n",
    "print('After:')\n",
    "pprint.pprint(full_eeg_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Compose the above all in one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'age': tensor(77.),\n",
      " 'class_label': tensor(1),\n",
      " 'class_name': 'Abnormal',\n",
      " 'serial': '01258',\n",
      " 'signal': tensor([[-12., -10., -17.,  ...,   6.,   3.,   7.],\n",
      "        [ 20.,  15.,  11.,  ...,  -1.,  -2., -12.],\n",
      "        [ 11.,   7.,   8.,  ...,  -2.,  -7.,  -6.],\n",
      "        ...,\n",
      "        [ -8., -12., -16.,  ...,   5.,   3.,   0.],\n",
      "        [ -2.,  -4.,  -4.,  ...,   1.,  -1.,  -1.],\n",
      "        [ 19.,  19.,  24.,  ..., -70., -58., -51.]]),\n",
      " 'symptom': ['dementia', 'vd', 'sivd']}\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    EegRandomCrop(crop_length=200*10,       # crop: 10s\n",
    "                  latency=200*10),          # latency: 10s\n",
    "    EegDropChannels(channel_photic), \n",
    "    EegToTensor()\n",
    "])\n",
    "\n",
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='abnormal',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='feather',\n",
    "                                                                                  transform=transform)\n",
    "\n",
    "pprint.pprint(train_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---\n",
    "\n",
    "## PyTorch DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if device.type == 'cuda':\n",
    "    num_workers = 0  # A number other than 0 causes an error\n",
    "    pin_memory = True\n",
    "else:\n",
    "    num_workers = 0\n",
    "    pin_memory = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'age': tensor([81., 84., 66., 69.]),\n",
      " 'serial': ['01093', '01011', '00084', '01087'],\n",
      " 'signal': tensor([[[ 257.,  252.,  257.,  ...,   23.,   21.,   20.],\n",
      "         [  59.,   58.,   57.,  ...,    4.,    3.,    2.],\n",
      "         [  -3.,   -3.,   -1.,  ...,   11.,   11.,    9.],\n",
      "         ...,\n",
      "         [ -13.,  -14.,  -13.,  ...,    4.,    8.,   10.],\n",
      "         [ -19.,  -16.,  -12.,  ...,   11.,   12.,    9.],\n",
      "         [-132., -133., -125.,  ...,  -59.,  -63.,  -68.]],\n",
      "\n",
      "        [[  34.,   30.,   25.,  ...,    6.,    4.,    3.],\n",
      "         [  31.,   25.,   20.,  ...,    1.,    2.,    1.],\n",
      "         [  -1.,    2.,    4.,  ...,   -6.,   -6.,   -5.],\n",
      "         ...,\n",
      "         [   9.,   13.,   14.,  ...,   -5.,   -6.,   -5.],\n",
      "         [ -13.,  -10.,   -8.,  ...,   -4.,   -6.,   -6.],\n",
      "         [  62.,   65.,   69.,  ...,  -19.,  -24.,  -29.]],\n",
      "\n",
      "        [[  -6.,   -5.,   -5.,  ...,  -24.,  -24.,  -23.],\n",
      "         [   7.,    8.,    8.,  ...,  -30.,  -26.,  -26.],\n",
      "         [  11.,    7.,    0.,  ...,   -6.,   -3.,   -4.],\n",
      "         ...,\n",
      "         [ -14.,  -10.,   -4.,  ...,    4.,    2.,    1.],\n",
      "         [   0.,    3.,    7.,  ...,   -3.,   -3.,   -2.],\n",
      "         [  27.,  -29.,   -9.,  ...,   13.,  -34.,   11.]],\n",
      "\n",
      "        [[ -24.,  -36.,  -25.,  ...,   30.,   36.,   39.],\n",
      "         [  -1.,  -12.,  -17.,  ...,   17.,   11.,    9.],\n",
      "         [  33.,   75.,  -27.,  ...,   16.,    6.,   -1.],\n",
      "         ...,\n",
      "         [   8.,    6.,   -2.,  ...,    5.,    4.,    5.],\n",
      "         [  12.,   12.,   12.,  ...,   -4.,   -5.,   -3.],\n",
      "         [ -11.,   12.,   -8.,  ...,    6.,   25.,   33.]]]),\n",
      " 'symptom': [['mci', 'mci_amnestic', 'mci_amnestic_rf'],\n",
      "             ['normal', 'smi'],\n",
      "             ['normal', 'cb_normal'],\n",
      "             ['normal', 'cb_normal']]}\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    EegRandomCrop(crop_length=200*10,       # crop: 10s\n",
    "                  latency=200*10),          # latency: 10s\n",
    "    EegDropChannels(channel_photic), \n",
    "    EegToTensor()\n",
    "])\n",
    "\n",
    "config_data, full_eeg_dataset = load_caueeg_full_dataset(dataset_path=data_path, \n",
    "                                                         load_event=False, \n",
    "                                                         file_format='feather',\n",
    "                                                         transform=transform)\n",
    "\n",
    "full_loader = DataLoader(full_eeg_dataset,\n",
    "                         batch_size=4,\n",
    "                         shuffle=True,\n",
    "                         drop_last=True,\n",
    "                         num_workers=num_workers,\n",
    "                         pin_memory=pin_memory,\n",
    "                         collate_fn=eeg_collate_fn)\n",
    "\n",
    "for i_batch, sample_batched in enumerate(full_loader):\n",
    "    pprint.pprint(sample_batched)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'age': tensor([62., 77., 65., 59., 76., 78., 60., 80.]),\n",
      " 'class_label': tensor([0, 1, 1, 0, 1, 0, 0, 1]),\n",
      " 'class_name': ['Normal', 'Abnormal', 'Abnormal', 'Normal', 'Abnormal', 'Normal', 'Normal', 'Abnormal'],\n",
      " 'serial': ['00098', '01021', '01219', '00787', '00722', '00298', '01139', '00259'],\n",
      " 'signal': tensor([[[ -31.,  -33.,  -33.,  ...,  716.,  663.,  672.],\n",
      "         [   0.,    0.,    0.,  ...,   81.,   76.,   34.],\n",
      "         [   7.,   10.,   12.,  ...,   45.,   30.,  -11.],\n",
      "         ...,\n",
      "         [ -16.,  -14.,  -10.,  ...,   11.,   20.,   16.],\n",
      "         [  -9.,   -7.,   -6.,  ...,   -9.,    1.,    3.],\n",
      "         [ -29.,  -36.,  -41.,  ...,   20.,   25.,   29.]],\n",
      "\n",
      "        [[  18.,   19.,   18.,  ...,    8.,   11.,   16.],\n",
      "         [  -5.,   -4.,   -3.,  ...,    9.,   12.,   17.],\n",
      "         [  -3.,   -7.,  -11.,  ...,   -4.,   -6.,   -7.],\n",
      "         ...,\n",
      "         [  -5.,   -5.,   -4.,  ...,   -2.,   -2.,   -4.],\n",
      "         [ -11.,  -14.,  -14.,  ...,   -6.,   -5.,   -6.],\n",
      "         [ -19.,  -22.,  -27.,  ...,  -14.,  -18.,  -18.]],\n",
      "\n",
      "        [[-134., -127., -123.,  ...,  -10.,  -12.,  -10.],\n",
      "         [ -39.,  -38.,  -39.,  ...,    2.,    0.,   -3.],\n",
      "         [   3.,    3.,    2.,  ...,  -12.,  -15.,  -16.],\n",
      "         ...,\n",
      "         [  20.,   20.,   21.,  ...,   14.,   12.,   12.],\n",
      "         [ -17.,  -15.,  -15.,  ...,    6.,    4.,    4.],\n",
      "         [  50.,   50.,   43.,  ...,   -8.,   -7.,   -4.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[   4.,    4.,    5.,  ...,    7.,    8.,    8.],\n",
      "         [   8.,    8.,    8.,  ...,    5.,    5.,    5.],\n",
      "         [  -4.,   -5.,   -5.,  ...,   16.,   17.,   18.],\n",
      "         ...,\n",
      "         [  -5.,   -8.,   -9.,  ...,   -5.,   -5.,   -5.],\n",
      "         [   3.,    1.,   -1.,  ...,   -1.,    0.,    1.],\n",
      "         [  53.,   60.,   56.,  ...,  -53.,  -39.,  -29.]],\n",
      "\n",
      "        [[  -4.,   -5.,   -5.,  ...,   -1.,   -1.,   -1.],\n",
      "         [   5.,    2.,    1.,  ...,    0.,    1.,    2.],\n",
      "         [   4.,    0.,   -1.,  ...,    2.,    1.,    1.],\n",
      "         ...,\n",
      "         [ -13.,  -15.,  -16.,  ...,    3.,    0.,   -1.],\n",
      "         [   1.,    0.,   -1.,  ...,    0.,   -5.,   -6.],\n",
      "         [  -4.,    3.,    1.,  ...,    4.,   -5.,   -2.]],\n",
      "\n",
      "        [[ -19.,  -22.,  -24.,  ...,  -21.,  -24.,  -28.],\n",
      "         [  -3.,   -7.,   -9.,  ...,   -6.,   -9.,  -12.],\n",
      "         [  -1.,    1.,    3.,  ...,    7.,    5.,    3.],\n",
      "         ...,\n",
      "         [  -1.,   -1.,   -1.,  ...,  -12.,  -14.,  -14.],\n",
      "         [   3.,    5.,    6.,  ...,   -2.,   -1.,    0.],\n",
      "         [   8.,    6.,    5.,  ...,    8.,    6.,   11.]]]),\n",
      " 'symptom': [['normal', 'smi'], ['mci', 'mci_amnestic'], ['tga'], ['normal', 'cb_normal'], ['mci', 'mci_amnestic'], ['normal', 'smi'], ['normal', 'cb_normal'], ['dementia', 'vd', 'sivd']]}\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    EegRandomCrop(crop_length=200*10,       # crop: 10s\n",
    "                  latency=200*10),          # latency: 10s\n",
    "    EegDropChannels(channel_photic), \n",
    "    EegToTensor()\n",
    "])\n",
    "\n",
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='abnormal',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='feather',\n",
    "                                                                                  transform=transform)\n",
    "\n",
    "test_loader = DataLoader(test_dataset,\n",
    "                          batch_size=8,\n",
    "                          shuffle=True,\n",
    "                          drop_last=True,\n",
    "                          num_workers=num_workers,\n",
    "                          pin_memory=pin_memory,\n",
    "                          collate_fn=eeg_collate_fn)\n",
    "\n",
    "for i_batch, sample_batched in enumerate(test_loader):\n",
    "    pprint.pprint(sample_batched, width=250)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---\n",
    "\n",
    "## Some preprocessing steps can be implemented via the PyTorch Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    EegRandomCrop(crop_length=200*10,       # crop: 10s\n",
    "                  latency=200*10),          # latency: 10s\n",
    "    EegDropChannels(channel_photic), \n",
    "    EegToTensor()\n",
    "])\n",
    "\n",
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='dementia',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='feather',\n",
    "                                                                                  transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                          batch_size=2,\n",
    "                          shuffle=True,\n",
    "                          drop_last=True,\n",
    "                          num_workers=num_workers,\n",
    "                          pin_memory=pin_memory,\n",
    "                          collate_fn=eeg_collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### To GPU device if it is possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n",
      "\n",
      "Sequential(\n",
      "  (0): EegToDevice(device=cuda)\n",
      ")\n",
      "- Before -\n",
      "{'age': tensor([70., 68.]),\n",
      " 'class_label': tensor([1, 0]),\n",
      " 'class_name': ['MCI', 'Normal'],\n",
      " 'serial': ['00388', '01022'],\n",
      " 'signal': tensor([[[-10., -11., -12.,  ..., -15., -17., -17.],\n",
      "         [ 12.,   9.,   8.,  ...,  14.,  15.,  16.],\n",
      "         [  0.,  -4.,  -7.,  ...,  -8.,  -7.,  -6.],\n",
      "         ...,\n",
      "         [ 10.,  11.,  11.,  ...,   6.,   8.,   9.],\n",
      "         [ -6.,  -6.,  -6.,  ...,  -7.,  -7.,  -6.],\n",
      "         [ 31.,  30.,  29.,  ..., -11., -18., -21.]],\n",
      "\n",
      "        [[ 19.,  21.,  17.,  ..., -11.,  -8.,  -4.],\n",
      "         [ -5.,   2.,   2.,  ...,  -6.,  -8.,  -7.],\n",
      "         [  1.,  -1.,  -2.,  ...,  -3.,  -4.,  -2.],\n",
      "         ...,\n",
      "         [  5.,   7.,   8.,  ...,  -5.,  -3.,   1.],\n",
      "         [  0.,   0.,   1.,  ...,  -2.,   0.,   0.],\n",
      "         [  0.,   5.,   4.,  ..., -27., -25., -21.]]]),\n",
      " 'symptom': [['mci', 'mci_vascular'], ['normal', 'smi']]}\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "- After -\n",
      "{'age': tensor([70., 68.], device='cuda:0'),\n",
      " 'class_label': tensor([1, 0], device='cuda:0'),\n",
      " 'class_name': ['MCI', 'Normal'],\n",
      " 'serial': ['00388', '01022'],\n",
      " 'signal': tensor([[[-10., -11., -12.,  ..., -15., -17., -17.],\n",
      "         [ 12.,   9.,   8.,  ...,  14.,  15.,  16.],\n",
      "         [  0.,  -4.,  -7.,  ...,  -8.,  -7.,  -6.],\n",
      "         ...,\n",
      "         [ 10.,  11.,  11.,  ...,   6.,   8.,   9.],\n",
      "         [ -6.,  -6.,  -6.,  ...,  -7.,  -7.,  -6.],\n",
      "         [ 31.,  30.,  29.,  ..., -11., -18., -21.]],\n",
      "\n",
      "        [[ 19.,  21.,  17.,  ..., -11.,  -8.,  -4.],\n",
      "         [ -5.,   2.,   2.,  ...,  -6.,  -8.,  -7.],\n",
      "         [  1.,  -1.,  -2.,  ...,  -3.,  -4.,  -2.],\n",
      "         ...,\n",
      "         [  5.,   7.,   8.,  ...,  -5.,  -3.,   1.],\n",
      "         [  0.,   0.,   1.,  ...,  -2.,   0.,   0.],\n",
      "         [  0.,   5.,   4.,  ..., -27., -25., -21.]]], device='cuda:0'),\n",
      " 'symptom': [['mci', 'mci_vascular'], ['normal', 'smi']]}\n"
     ]
    }
   ],
   "source": [
    "print('device:', device)\n",
    "print()\n",
    "\n",
    "preprocess_train = transforms.Compose([EegToDevice(device=device)])\n",
    "preprocess_train = torch.nn.Sequential(*preprocess_train.transforms).to(device)\n",
    "pprint.pprint(preprocess_train)\n",
    "\n",
    "for i_batch, sample_batched in enumerate(train_loader):\n",
    "    print('- Before -')\n",
    "    pprint.pprint(sample_batched)\n",
    "\n",
    "    print()\n",
    "    print('-' * 100)\n",
    "    print()\n",
    "    \n",
    "    preprocess_train(sample_batched)\n",
    "    \n",
    "    print('- After -')\n",
    "    pprint.pprint(sample_batched)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Normalization per signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): EegToDevice(device=cuda)\n",
      "  (1): EegNormalizePerSignal(eps=1e-08)\n",
      ")\n",
      "- Before -\n",
      "Mean: tensor([[-1.5015, -1.2540,  0.9750, -0.2035, -0.0120, -1.4020, -0.4920,  0.0750,\n",
      "          0.2650, -0.0150, -0.9570,  1.1425, -0.8590, -0.0855,  3.0465, -0.0670,\n",
      "          0.0280, -1.1910, -0.3915, -0.4005],\n",
      "        [-3.2060, -0.2100,  0.4410,  0.3770,  0.2915,  0.4115, -1.1685,  0.4630,\n",
      "          0.7025,  0.6765, -0.7380,  0.0970, -0.2030, -1.7420, -1.9505,  0.0985,\n",
      "          1.9050, -1.0475, -0.0145,  0.7985]])\n",
      "\n",
      "Std: tensor([[10.2681,  7.4200,  7.0835,  7.6284,  8.2955, 10.5996,  9.6177,  7.0683,\n",
      "          6.9477,  6.7667,  9.3398, 10.4793, 12.0134,  8.6347, 10.9687,  8.9374,\n",
      "          7.0422,  6.1566,  6.0609, 21.0069],\n",
      "        [20.7061, 16.6624,  6.5889,  7.0615,  9.6049, 19.0360, 11.9814,  5.1844,\n",
      "          5.9414,  9.9172, 14.4610,  9.2566, 10.6721, 15.0691, 12.9404,  6.6295,\n",
      "         24.6432, 11.8071,  7.4599, 65.7220]])\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "- After -\n",
      "Mean: tensor([[ 0.0000e+00,  1.3351e-08, -8.1062e-09, -1.5259e-08, -1.9073e-09,\n",
      "          1.9073e-08, -5.2452e-09,  3.8147e-09,  3.8147e-09,  7.6294e-09,\n",
      "         -9.0599e-09,  1.1444e-08,  2.3842e-09,  7.6294e-09, -2.8610e-08,\n",
      "          3.8147e-09,  9.5367e-09, -4.7684e-09,  1.5259e-08,  0.0000e+00],\n",
      "        [-5.7220e-09,  2.2888e-08,  4.7684e-09,  3.8147e-09, -9.5367e-09,\n",
      "          1.9073e-08, -1.9073e-08, -1.4305e-08,  1.1444e-08, -6.1989e-09,\n",
      "          0.0000e+00, -7.6294e-09, -1.5259e-08,  2.5749e-08, -7.6294e-09,\n",
      "          4.7684e-10,  1.1444e-08,  3.8147e-09, -1.2398e-08,  8.5831e-09]],\n",
      "       device='cuda:0')\n",
      "\n",
      "Std: tensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "preprocess_train = transforms.Compose([\n",
    "    EegToDevice(device=device), \n",
    "    EegNormalizePerSignal()\n",
    "])\n",
    "preprocess_train = torch.nn.Sequential(*preprocess_train.transforms).to(device)\n",
    "pprint.pprint(preprocess_train)\n",
    "\n",
    "for i_batch, sample_batched in enumerate(train_loader):\n",
    "    print('- Before -')\n",
    "    print('Mean:', torch.mean(sample_batched['signal'], axis=-1))\n",
    "    print()\n",
    "    print('Std:', torch.std(sample_batched['signal'], axis=-1))\n",
    "\n",
    "    print()\n",
    "    print('-' * 100)\n",
    "    print()\n",
    "    \n",
    "    preprocess_train(sample_batched)\n",
    "    \n",
    "    print('- After -')\n",
    "    print('Mean:', torch.mean(sample_batched['signal'], axis=-1))\n",
    "    print()\n",
    "    print('Std:', torch.std(sample_batched['signal'], axis=-1))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Signal normalization using the specified mean and std values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean and standard deviation for signal:\n",
      "tensor([[[-0.0340],\n",
      "         [ 0.0634],\n",
      "         [ 0.0308],\n",
      "         [-0.0197],\n",
      "         [-0.0238],\n",
      "         [-0.0111],\n",
      "         [-0.0413],\n",
      "         [ 0.0295],\n",
      "         [ 0.0091],\n",
      "         [ 0.0030],\n",
      "         [ 0.0294],\n",
      "         [-0.0206],\n",
      "         [-0.0196],\n",
      "         [-0.0190],\n",
      "         [-0.0312],\n",
      "         [-0.0034],\n",
      "         [-0.0349],\n",
      "         [ 0.0046],\n",
      "         [ 0.0249],\n",
      "         [-0.0021]]])\n",
      "-\n",
      "tensor([[[45.1173],\n",
      "         [20.5836],\n",
      "         [11.8230],\n",
      "         [11.7496],\n",
      "         [15.7130],\n",
      "         [48.4388],\n",
      "         [19.9356],\n",
      "         [10.5975],\n",
      "         [11.8556],\n",
      "         [16.0715],\n",
      "         [20.9259],\n",
      "         [14.4848],\n",
      "         [13.7052],\n",
      "         [21.9231],\n",
      "         [16.7736],\n",
      "         [14.9407],\n",
      "         [19.5530],\n",
      "         [11.3869],\n",
      "         [11.5357],\n",
      "         [93.8896]]])\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Sequential(\n",
      "  (0): EegToDevice(device=cuda)\n",
      "  (1): EegNormalizeMeanStd(mean=tensor([-0.0340,  0.0634,  0.0308, -0.0197, -0.0238, -0.0111, -0.0413,  0.0295,\n",
      "           0.0091,  0.0030,  0.0294, -0.0206, -0.0196, -0.0190, -0.0312, -0.0034,\n",
      "          -0.0349,  0.0046,  0.0249, -0.0021]),std=tensor([45.1173, 20.5836, 11.8230, 11.7496, 15.7130, 48.4388, 19.9356, 10.5975,\n",
      "          11.8556, 16.0715, 20.9259, 14.4848, 13.7052, 21.9231, 16.7736, 14.9407,\n",
      "          19.5530, 11.3869, 11.5357, 93.8896]),eps=1e-08)\n",
      ")\n",
      "- Before -\n",
      "Mean: tensor([[ 1.5033e+01, -2.8129e+01,  3.2222e+01,  1.2515e+00,  1.0292e+01,\n",
      "         -9.0537e+01, -1.3480e+02, -7.9395e+00,  2.5586e+01,  4.7869e+01,\n",
      "         -2.1565e+00, -1.0619e+01, -6.1210e+00, -3.1576e+01, -7.2180e+00,\n",
      "          3.8522e+01, -2.2501e+01,  7.3465e+01,  2.1770e+01,  2.9850e-01],\n",
      "        [ 2.3805e+00,  1.3935e+00,  8.9300e-01, -1.3100e-01, -1.0395e+00,\n",
      "         -1.5555e+00, -6.7550e-01, -4.8900e-01, -3.7850e-01, -4.5850e-01,\n",
      "          3.0880e+00,  3.7500e-01, -1.1900e-01, -1.9840e+00, -1.2810e+00,\n",
      "         -5.3650e-01,  6.1750e-01,  2.4550e-01,  4.3750e-01, -3.5000e-01]])\n",
      "\n",
      "Std: tensor([[128.2638, 210.7076, 121.5048, 303.1442, 288.6232, 619.3406, 754.5778,\n",
      "         155.8704,  61.1905, 135.8073, 100.1431, 128.6244, 240.2696, 564.8564,\n",
      "          87.0779, 144.6932,  81.2548, 324.6803, 266.9412,  58.1397],\n",
      "        [ 29.4487,  19.6180,  11.2609,  10.1467,   5.9529,  53.1604,  19.4763,\n",
      "           8.3993,   5.2791,   6.1748,  36.5797,  11.5619,   7.4721,  41.0071,\n",
      "          15.0787,   9.5423,   8.8466,   8.8031,   6.6447,  71.0452]])\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "- After -\n",
      "Mean: tensor([[ 3.3396e-01, -1.3697e+00,  2.7228e+00,  1.0819e-01,  6.5652e-01,\n",
      "         -1.8689e+00, -6.7599e+00, -7.5197e-01,  2.1573e+00,  2.9783e+00,\n",
      "         -1.0446e-01, -7.3169e-01, -4.4519e-01, -1.4395e+00, -4.2846e-01,\n",
      "          2.5786e+00, -1.1490e+00,  6.4514e+00,  1.8850e+00,  3.2015e-03],\n",
      "        [ 5.3516e-02,  6.4618e-02,  7.2926e-02, -9.4740e-03, -6.4638e-02,\n",
      "         -3.1885e-02, -3.1815e-02, -4.8924e-02, -3.2691e-02, -2.8713e-02,\n",
      "          1.4616e-01,  2.7312e-02, -7.2543e-03, -8.9633e-02, -7.4509e-02,\n",
      "         -3.5679e-02,  3.3364e-02,  2.1159e-02,  3.5763e-02, -3.7056e-03]],\n",
      "       device='cuda:0')\n",
      "\n",
      "Std: tensor([[ 2.8429, 10.2367, 10.2770, 25.8003, 18.3684, 12.7860, 37.8508, 14.7082,\n",
      "          5.1613,  8.4502,  4.7856,  8.8800, 17.5312, 25.7654,  5.1914,  9.6845,\n",
      "          4.1556, 28.5136, 23.1405,  0.6192],\n",
      "        [ 0.6527,  0.9531,  0.9525,  0.8636,  0.3788,  1.0975,  0.9770,  0.7926,\n",
      "          0.4453,  0.3842,  1.7481,  0.7982,  0.5452,  1.8705,  0.8990,  0.6387,\n",
      "          0.4524,  0.7731,  0.5760,  0.7567]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "signal_mean, signal_std = calculate_signal_statistics(train_loader, repeats=30, verbose=True)\n",
    "\n",
    "preprocess_train = transforms.Compose([\n",
    "    EegToDevice(device=device), \n",
    "    EegNormalizeMeanStd(mean=signal_mean, std=signal_std)\n",
    "])\n",
    "preprocess_train = torch.nn.Sequential(*preprocess_train.transforms).to(device)\n",
    "pprint.pprint(preprocess_train)\n",
    "\n",
    "for i_batch, sample_batched in enumerate(train_loader):\n",
    "    print('- Before -')\n",
    "    print('Mean:', torch.mean(sample_batched['signal'], axis=-1))\n",
    "    print()\n",
    "    print('Std:', torch.std(sample_batched['signal'], axis=-1))\n",
    "\n",
    "    print()\n",
    "    print('-' * 100)\n",
    "    print()\n",
    "    \n",
    "    preprocess_train(sample_batched)\n",
    "    \n",
    "    print('- After -')\n",
    "    print('Mean:', torch.mean(sample_batched['signal'], axis=-1))\n",
    "    print()\n",
    "    print('Std:', torch.std(sample_batched['signal'], axis=-1))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Age normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age mean and standard deviation:\n",
      "tensor([71.2453]) tensor([7.8228])\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Sequential(\n",
      "  (0): EegToDevice(device=cuda)\n",
      "  (1): EegNormalizeAge(mean=tensor([71.2453]),std=tensor([7.8228]),eps=1e-08)\n",
      ")\n",
      "- Before -\n",
      "tensor([67., 68.])\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "- After -\n",
      "tensor([-0.5427, -0.4148], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "age_mean, age_std = calculate_age_statistics(train_loader, verbose=True)\n",
    "\n",
    "preprocess_train = transforms.Compose([\n",
    "    EegToDevice(device=device), \n",
    "    EegNormalizeAge(mean=age_mean, std=age_std)\n",
    "])\n",
    "preprocess_train = torch.nn.Sequential(*preprocess_train.transforms).to(device)\n",
    "pprint.pprint(preprocess_train)\n",
    "\n",
    "for i_batch, sample_batched in enumerate(train_loader):\n",
    "    print('- Before -')\n",
    "    pprint.pprint(sample_batched['age'])\n",
    "\n",
    "    print()\n",
    "    print('-' * 100)\n",
    "    print()\n",
    "    \n",
    "    preprocess_train(sample_batched)\n",
    "    \n",
    "    print('- After -')\n",
    "    pprint.pprint(sample_batched['age'])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Short time Fourier transform (STFT or spectrogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): EegToDevice(device=cuda)\n",
      "  (1): EegSpectrogram(n_fft=200, complex_mode=as_real, stft_kwargs={})\n",
      ")\n",
      "- Before -\n",
      "torch.Size([2, 20, 2000])\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "- After -\n",
      "torch.Size([2, 40, 101, 41])\n"
     ]
    }
   ],
   "source": [
    "preprocess_train = transforms.Compose([\n",
    "    EegToDevice(device=device), \n",
    "    EegSpectrogram(n_fft=200, complex_mode='as_real')\n",
    "])\n",
    "preprocess_train = torch.nn.Sequential(*preprocess_train.transforms).to(device)\n",
    "pprint.pprint(preprocess_train)\n",
    "\n",
    "for i_batch, sample_batched in enumerate(train_loader):\n",
    "    print('- Before -')\n",
    "    pprint.pprint(sample_batched['signal'].shape)\n",
    "\n",
    "    print()\n",
    "    print('-' * 100)\n",
    "    print()\n",
    "    \n",
    "    preprocess_train(sample_batched)\n",
    "    \n",
    "    print('- After -')\n",
    "    pprint.pprint(sample_batched['signal'].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "## Speed check without STFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "crop_length = 200 * 10\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### `EDF`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compose(\n",
      "    EegRandomCrop(crop_length=2000, length_limit=10000000, multiple=1, latency=2000, return_timing=False)\n",
      "    EegDropChannels(drop_index=20)\n",
      "    EegToTensor()\n",
      ")\n",
      "Sequential(\n",
      "  (0): EegToDevice(device=cuda)\n",
      "  (1): EegNormalizeAge(mean=tensor([71.2453]),std=tensor([7.8228]),eps=1e-08)\n",
      "  (2): EegNormalizeMeanStd(mean=tensor([-0.0340,  0.0634,  0.0308, -0.0197, -0.0238, -0.0111, -0.0413,  0.0295,\n",
      "           0.0091,  0.0030,  0.0294, -0.0206, -0.0196, -0.0190, -0.0312, -0.0034,\n",
      "          -0.0349,  0.0046,  0.0249, -0.0021]),std=tensor([45.1173, 20.5836, 11.8230, 11.7496, 15.7130, 48.4388, 19.9356, 10.5975,\n",
      "          11.8556, 16.0715, 20.9259, 14.4848, 13.7052, 21.9231, 16.7736, 14.9407,\n",
      "          19.5530, 11.3869, 11.5357, 93.8896]),eps=1e-08)\n",
      ")\n",
      "CPU times: total: 23min 8s\n",
      "Wall time: 1min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "transform = transforms.Compose([\n",
    "    EegRandomCrop(crop_length=crop_length,\n",
    "                  latency=200*10),          # latency: 10s\n",
    "    EegDropChannels(channel_photic), \n",
    "    EegToTensor()\n",
    "])\n",
    "pprint.pprint(transform)\n",
    "\n",
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='dementia',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='edf',\n",
    "                                                                                  transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True,\n",
    "                          drop_last=True,\n",
    "                          num_workers=num_workers,\n",
    "                          pin_memory=pin_memory,\n",
    "                          collate_fn=eeg_collate_fn)\n",
    "\n",
    "preprocess_train = transforms.Compose([\n",
    "    EegToDevice(device=device), \n",
    "    EegNormalizeAge(mean=age_mean, std=age_std), \n",
    "    EegNormalizeMeanStd(mean=signal_mean, std=signal_std)\n",
    "])\n",
    "preprocess_train = torch.nn.Sequential(*preprocess_train.transforms).to(device)\n",
    "pprint.pprint(preprocess_train)\n",
    "\n",
    "for i_batch, sample_batched in enumerate(train_loader):\n",
    "    preprocess_train(sample_batched)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### `feather`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compose(\n",
      "    EegRandomCrop(crop_length=2000, length_limit=10000000, multiple=1, latency=2000, return_timing=False)\n",
      "    EegDropChannels(drop_index=20)\n",
      "    EegToTensor()\n",
      ")\n",
      "Sequential(\n",
      "  (0): EegToDevice(device=cuda)\n",
      "  (1): EegNormalizeAge(mean=tensor([71.2453]),std=tensor([7.8228]),eps=1e-08)\n",
      "  (2): EegNormalizeMeanStd(mean=tensor([-0.0340,  0.0634,  0.0308, -0.0197, -0.0238, -0.0111, -0.0413,  0.0295,\n",
      "           0.0091,  0.0030,  0.0294, -0.0206, -0.0196, -0.0190, -0.0312, -0.0034,\n",
      "          -0.0349,  0.0046,  0.0249, -0.0021]),std=tensor([45.1173, 20.5836, 11.8230, 11.7496, 15.7130, 48.4388, 19.9356, 10.5975,\n",
      "          11.8556, 16.0715, 20.9259, 14.4848, 13.7052, 21.9231, 16.7736, 14.9407,\n",
      "          19.5530, 11.3869, 11.5357, 93.8896]),eps=1e-08)\n",
      ")\n",
      "CPU times: total: 50 s\n",
      "Wall time: 3.28 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    EegRandomCrop(crop_length=crop_length,\n",
    "                  latency=200*10),          # latency: 10s\n",
    "    EegDropChannels(channel_photic), \n",
    "    EegToTensor()\n",
    "])\n",
    "pprint.pprint(transform)\n",
    "\n",
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='dementia',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='feather',\n",
    "                                                                                  transform=transform)\n",
    " \n",
    "train_loader = DataLoader(train_dataset,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True,\n",
    "                          drop_last=True,\n",
    "                          num_workers=num_workers,\n",
    "                          pin_memory=pin_memory,\n",
    "                          collate_fn=eeg_collate_fn)\n",
    "\n",
    "preprocess_train = transforms.Compose([\n",
    "    EegToDevice(device=device), \n",
    "    EegNormalizeAge(mean=age_mean, std=age_std), \n",
    "    EegNormalizeMeanStd(mean=signal_mean, std=signal_std)\n",
    "])\n",
    "preprocess_train = torch.nn.Sequential(*preprocess_train.transforms).to(device)\n",
    "pprint.pprint(preprocess_train)\n",
    "\n",
    "for i_batch, sample_batched in enumerate(train_loader):\n",
    "    preprocess_train(sample_batched)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "## Speed check with STFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sequence length: (3000) would become (78, 77) after the STFT with n_fft (155) and hop_length (39).\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "crop_length = 300 * 10\n",
    "n_fft, hop_length, seq_len_2d = calculate_stft_params(seq_length=crop_length, verbose=True)\n",
    "batch_size = 128\n",
    "\n",
    "preprocess_train = transforms.Compose([\n",
    "    EegToDevice(device=device), \n",
    "    EegSpectrogram(n_fft=n_fft, hop_length=hop_length, complex_mode='as_real')\n",
    "])\n",
    "preprocess_train = torch.nn.Sequential(*preprocess_train.transforms).to(device)\n",
    "signal_2d_mean, signal_2d_std = calculate_signal_statistics(train_loader, preprocess_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### `EDF`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compose(\n",
      "    EegRandomCrop(crop_length=3000, length_limit=10000000, multiple=1, latency=2000, return_timing=False)\n",
      "    EegDropChannels(drop_index=20)\n",
      "    EegToTensor()\n",
      ")\n",
      "Sequential(\n",
      "  (0): EegToDevice(device=cuda)\n",
      "  (1): EegNormalizeAge(mean=tensor([71.2453]),std=tensor([7.8228]),eps=1e-08)\n",
      "  (2): EegSpectrogram(n_fft=155, complex_mode=as_real, stft_kwargs={'hop_length': 39})\n",
      "  (3): EegNormalizeMeanStd(mean=tensor([[-3.9695e+01, -4.8631e-01, -1.2728e-01,  ..., -2.1061e-03,\n",
      "            2.9554e-02,  2.1025e-02],\n",
      "          [ 1.3874e+01, -1.0662e-01, -7.5962e-02,  ...,  6.4494e-03,\n",
      "            8.2820e-03,  6.8985e-03],\n",
      "          [ 9.4372e+00,  1.4145e-01, -9.2469e-03,  ...,  2.0075e-02,\n",
      "            1.7569e-02,  1.7965e-02],\n",
      "          ...,\n",
      "          [ 0.0000e+00,  9.7692e-01,  4.0125e-01,  ..., -8.8930e-03,\n",
      "            8.9706e-03,  2.4872e-03],\n",
      "          [ 0.0000e+00,  1.3422e+00,  5.8539e-01,  ...,  4.4170e-03,\n",
      "           -4.2220e-03,  3.9863e-04],\n",
      "          [ 0.0000e+00, -1.3657e+00, -3.2132e-01,  ...,  8.9221e-03,\n",
      "           -6.4601e-03, -1.3152e-03]], device='cuda:0'),std=tensor([[5.9024e+03, 1.0068e+03, 5.0110e+02,  ..., 2.6209e+01, 2.6175e+01,\n",
      "           2.6201e+01],\n",
      "          [2.6714e+03, 4.0342e+02, 2.0742e+02,  ..., 1.2276e+01, 1.2253e+01,\n",
      "           1.2271e+01],\n",
      "          [1.4923e+03, 2.0559e+02, 1.1739e+02,  ..., 7.6651e+00, 7.6207e+00,\n",
      "           7.6476e+00],\n",
      "          ...,\n",
      "          [0.0000e+00, 3.2304e+02, 1.8352e+02,  ..., 2.5584e+00, 2.5904e+00,\n",
      "           2.6091e+00],\n",
      "          [0.0000e+00, 3.4486e+02, 1.8998e+02,  ..., 2.5694e+00, 2.5924e+00,\n",
      "           2.6100e+00],\n",
      "          [0.0000e+00, 1.9496e+03, 2.0563e+03,  ..., 5.7880e+00, 5.4937e+00,\n",
      "           4.7781e+00]], device='cuda:0'),eps=1e-08)\n",
      ")\n",
      "torch.Size([128, 40, 78, 77])\n",
      "CPU times: total: 23min 18s\n",
      "Wall time: 1min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    EegRandomCrop(crop_length=crop_length,\n",
    "                  latency=200*10),          # latency: 10s\n",
    "    EegDropChannels(channel_photic), \n",
    "    EegToTensor()\n",
    "])\n",
    "pprint.pprint(transform)\n",
    "\n",
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='dementia',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='edf',\n",
    "                                                                                  transform=transform)\n",
    " \n",
    "train_loader = DataLoader(train_dataset,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True,\n",
    "                          drop_last=True,\n",
    "                          num_workers=num_workers,\n",
    "                          pin_memory=pin_memory,\n",
    "                          collate_fn=eeg_collate_fn)\n",
    "\n",
    "preprocess_train = transforms.Compose([\n",
    "    EegToDevice(device=device), \n",
    "    EegNormalizeAge(mean=age_mean, std=age_std), \n",
    "    EegSpectrogram(n_fft=n_fft, hop_length=hop_length, complex_mode='as_real'),\n",
    "    EegNormalizeMeanStd(mean=signal_2d_mean, std=signal_2d_std),\n",
    "])\n",
    "preprocess_train = torch.nn.Sequential(*preprocess_train.transforms).to(device)\n",
    "pprint.pprint(preprocess_train)\n",
    "\n",
    "for i_batch, sample_batched in enumerate(train_loader):\n",
    "    preprocess_train(sample_batched)\n",
    "    size = sample_batched['signal'].size()\n",
    "    \n",
    "print(size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### `PyArrow.feather`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compose(\n",
      "    EegRandomCrop(crop_length=3000, length_limit=10000000, multiple=1, latency=2000, return_timing=False)\n",
      "    EegDropChannels(drop_index=20)\n",
      "    EegToTensor()\n",
      ")\n",
      "Sequential(\n",
      "  (0): EegToDevice(device=cuda)\n",
      "  (1): EegNormalizeAge(mean=tensor([71.2453]),std=tensor([7.8228]),eps=1e-08)\n",
      "  (2): EegSpectrogram(n_fft=155, complex_mode=as_real, stft_kwargs={'hop_length': 39})\n",
      "  (3): EegNormalizeMeanStd(mean=tensor([[-3.9695e+01, -4.8631e-01, -1.2728e-01,  ..., -2.1061e-03,\n",
      "            2.9554e-02,  2.1025e-02],\n",
      "          [ 1.3874e+01, -1.0662e-01, -7.5962e-02,  ...,  6.4494e-03,\n",
      "            8.2820e-03,  6.8985e-03],\n",
      "          [ 9.4372e+00,  1.4145e-01, -9.2469e-03,  ...,  2.0075e-02,\n",
      "            1.7569e-02,  1.7965e-02],\n",
      "          ...,\n",
      "          [ 0.0000e+00,  9.7692e-01,  4.0125e-01,  ..., -8.8930e-03,\n",
      "            8.9706e-03,  2.4872e-03],\n",
      "          [ 0.0000e+00,  1.3422e+00,  5.8539e-01,  ...,  4.4170e-03,\n",
      "           -4.2220e-03,  3.9863e-04],\n",
      "          [ 0.0000e+00, -1.3657e+00, -3.2132e-01,  ...,  8.9221e-03,\n",
      "           -6.4601e-03, -1.3152e-03]], device='cuda:0'),std=tensor([[5.9024e+03, 1.0068e+03, 5.0110e+02,  ..., 2.6209e+01, 2.6175e+01,\n",
      "           2.6201e+01],\n",
      "          [2.6714e+03, 4.0342e+02, 2.0742e+02,  ..., 1.2276e+01, 1.2253e+01,\n",
      "           1.2271e+01],\n",
      "          [1.4923e+03, 2.0559e+02, 1.1739e+02,  ..., 7.6651e+00, 7.6207e+00,\n",
      "           7.6476e+00],\n",
      "          ...,\n",
      "          [0.0000e+00, 3.2304e+02, 1.8352e+02,  ..., 2.5584e+00, 2.5904e+00,\n",
      "           2.6091e+00],\n",
      "          [0.0000e+00, 3.4486e+02, 1.8998e+02,  ..., 2.5694e+00, 2.5924e+00,\n",
      "           2.6100e+00],\n",
      "          [0.0000e+00, 1.9496e+03, 2.0563e+03,  ..., 5.7880e+00, 5.4937e+00,\n",
      "           4.7781e+00]], device='cuda:0'),eps=1e-08)\n",
      ")\n",
      "torch.Size([128, 40, 78, 77])\n",
      "CPU times: total: 53.9 s\n",
      "Wall time: 3.53 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    EegRandomCrop(crop_length=crop_length,\n",
    "                  latency=200*10),          # latency: 10s\n",
    "    EegDropChannels(channel_photic), \n",
    "    EegToTensor()\n",
    "])\n",
    "pprint.pprint(transform)\n",
    "\n",
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='dementia',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='feather',\n",
    "                                                                                  transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True,\n",
    "                          drop_last=True,\n",
    "                          num_workers=num_workers,\n",
    "                          pin_memory=pin_memory,\n",
    "                          collate_fn=eeg_collate_fn)\n",
    "\n",
    "preprocess_train = transforms.Compose([\n",
    "    EegToDevice(device=device), \n",
    "    EegNormalizeAge(mean=age_mean, std=age_std), \n",
    "    EegSpectrogram(n_fft=n_fft, hop_length=hop_length, complex_mode='as_real'),\n",
    "    EegNormalizeMeanStd(mean=signal_2d_mean, std=signal_2d_std),\n",
    "])\n",
    "preprocess_train = torch.nn.Sequential(*preprocess_train.transforms).to(device)\n",
    "pprint.pprint(preprocess_train)\n",
    "\n",
    "for i_batch, sample_batched in enumerate(train_loader):\n",
    "    preprocess_train(sample_batched)\n",
    "    size = sample_batched['signal'].size()\n",
    "    \n",
    "print(size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "37e0b27a9710fa201e26169906fbd4cae3a7652e9e1c64cf2110e48663b0b7d0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
